import sqlite3, json, os, sys

DB_PATH = "/opt/aura-assistant/db.sqlite3"

DDL = """
CREATE TABLE IF NOT EXISTS entities (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  user_id INTEGER NOT NULL,
  type TEXT NOT NULL,             -- 'list', 'task', 'note', 'reminder', ...
  title TEXT,                     -- Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾Ðµ Ð¸Ð¼Ñ/Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ
  content TEXT,                   -- ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚/Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ
  parent_id INTEGER,              -- ÑÑÑ‹Ð»ÐºÐ° Ð½Ð° Ñ€Ð¾Ð´Ð¸Ñ‚ÐµÐ»Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, task->list)
  created_at TEXT DEFAULT CURRENT_TIMESTAMP,
  meta TEXT,                      -- JSON-Ð¿Ð¾Ð»Ðµ Ð´Ð»Ñ Ð³Ð¸Ð±ÐºÐ¸Ñ… ÑÐ²Ð¾Ð¹ÑÑ‚Ð²
  UNIQUE(user_id, type, title, parent_id)
);
"""

def table_exists(conn, name):
    cur = conn.cursor()
    cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (name,))
    return cur.fetchone() is not None

def migrate_lists_tasks(conn):
    cur = conn.cursor()

    # Ð•ÑÐ»Ð¸ ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ð½ÐµÑ‚ â€” Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð²Ñ‹Ñ…Ð¾Ð´Ð¸Ð¼
    if not table_exists(conn, "lists") and not table_exists(conn, "tasks"):
        return

    # ÐŸÐ¾Ð´Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð’Ð¡Ð• ÑÐ¿Ð¸ÑÐºÐ¸ (ÐµÑÐ»Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° ÐµÑÑ‚ÑŒ)
    lists = []
    if table_exists(conn, "lists"):
        cur.execute("PRAGMA table_info(lists)")
        cols = [c[1] for c in cur.fetchall()]
        # Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼: user_id, name
        if set(["user_id","name"]).issubset(set(cols)):
            cur.execute("SELECT DISTINCT user_id, name FROM lists")
            lists = cur.fetchall()

    # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¼ Ð¸Ð½Ð´ÐµÐºÑ Ð¸Ð¼Ñ‘Ð½ ÑÐ¿Ð¸ÑÐºÐ¾Ð² -> id entity
    list_id_by_key = {}  # (user_id, name) -> entity_id

    # Ð¡Ð¾Ð·Ð´Ð°Ð´Ð¸Ð¼ Ð·Ð°Ð¿Ð¸ÑÐ¸-ÑÐ¿Ð¸ÑÐºÐ¸ Ð² entities (idempotent)
    for user_id, name in lists:
        try:
            cur.execute("""
              INSERT OR IGNORE INTO entities (user_id, type, title)
              VALUES (?, 'list', ?)
            """, (user_id, name))
            conn.commit()
        except Exception:
            pass
        cur.execute("""
          SELECT id FROM entities WHERE user_id=? AND type='list' AND title=? LIMIT 1
        """, (user_id, name))
        row = cur.fetchone()
        if row:
            list_id_by_key[(user_id, name)] = row[0]

    # Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ð¸
    if table_exists(conn, "tasks"):
        cur.execute("PRAGMA table_info(tasks)")
        cols = [c[1] for c in cur.fetchall()]
        # Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼: user_id, list_name, task
        if set(["user_id","list_name","task"]).issubset(set(cols)):
            cur.execute("SELECT user_id, list_name, task FROM tasks")
            for user_id, list_name, task in cur.fetchall():
                # ÑƒÐ±ÐµÐ´Ð¸Ð¼ÑÑ, Ñ‡Ñ‚Ð¾ ÐµÑÑ‚ÑŒ list entity
                if (user_id, list_name) not in list_id_by_key:
                    # ÑÐ¾Ð·Ð´Ð°Ð´Ð¸Ð¼ ÑÐ¿Ð¸ÑÐ¾Ðº, ÐµÑÐ»Ð¸ Ð²Ð´Ñ€ÑƒÐ³ Ð½Ðµ Ð±Ñ‹Ð»Ð¾
                    cur.execute("""
                      INSERT OR IGNORE INTO entities (user_id, type, title)
                      VALUES (?, 'list', ?)
                    """, (user_id, list_name))
                    conn.commit()
                    cur.execute("""
                      SELECT id FROM entities WHERE user_id=? AND type='list' AND title=? LIMIT 1
                    """, (user_id, list_name))
                    r2 = cur.fetchone()
                    if r2: list_id_by_key[(user_id, list_name)] = r2[0]

                parent_id = list_id_by_key.get((user_id, list_name))
                # Ð´Ð¾Ð±Ð°Ð²Ð¸Ð¼ task
                cur.execute("""
                  INSERT OR IGNORE INTO entities (user_id, type, title, parent_id, meta)
                  VALUES (?, 'task', ?, ?, ?)
                """, (user_id, task, parent_id, json.dumps({"status": "open"})))
            conn.commit()

def main():
    if not os.path.exists(DB_PATH):
        print(f"DB not found: {DB_PATH}", file=sys.stderr)
        sys.exit(1)
    conn = sqlite3.connect(DB_PATH)
    try:
        with conn:
            conn.execute(DDL)
            migrate_lists_tasks(conn)
        print("Migration to entities: OK")
    finally:
        conn.close()

if __name__ == "__main__":
    main()
#!/bin/bash
# === Ð¡Ñ‚Ð°Ñ€Ñ‚ Aura Assistant (Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ + Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ) ===

cd /opt/aura-assistant || exit 1

# ÐÐºÑ‚Ð¸Ð²Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ
source venv/bin/activate

# Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð±Ð¾Ñ‚Ð°
python main.py >> /opt/aura-assistant/aura.log 2>&1 &
#!/bin/bash
# ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Aura Assistant
pkill -f "/opt/aura-assistant/main.py"
echo "ðŸ›‘ Aura Assistant Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½"
python-telegram-bot
speechrecognition
pydub
openai>=1.0.0
httpx
ffmpeg-python
#!/usr/bin/env bash
set -euo pipefail
TS=$(date +"%Y%m%d_%H%M%S")
OUT="/opt/aura-assistant/aura_support_$TS"
mkdir -p "$OUT"

# ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° (ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼, ÐµÑÐ»Ð¸ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‚)
for f in main.py db.py requirements.txt start.sh stop.sh docker-compose.yml pyproject.toml poetry.lock; do
  [ -f "$f" ] && cp -v "$f" "$OUT/" || true
done

# Ð›Ð¾Ð³Ð¸ (Ð±ÐµÑ€Ñ‘Ð¼ Ñ…Ð²Ð¾ÑÑ‚Ñ‹, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ñ‚ÑÐ½ÑƒÑ‚ÑŒ Ð³Ð¸Ð³Ð°Ð±Ð°Ð¹Ñ‚Ñ‹)
for f in aura.log aura.run.log openai_raw.log; do
  [ -f "$f" ] && tail -n 400 "$f" > "$OUT/${f}.tail.txt" || true
done

# systemd unit (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
if command -v systemctl >/dev/null 2>&1; then
  systemctl list-unit-files 2>/dev/null | grep -q '^aura-assistant\.service' && \
    systemctl cat aura-assistant.service > "$OUT/aura-assistant.service.txt" || true
fi

# .env (Ñ Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹)
if [ -f .env ]; then
  sed -E 's/^([A-Za-z0-9_]+)=.*/\1=***REDACTED*** /' .env > "$OUT/.env.redacted"
fi

# Ð’ÐµÑ€ÑÐ¸Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²/Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
python -V > "$OUT/python_version.txt" 2>&1 || true
pip freeze > "$OUT/pip_freeze.txt" 2>/dev/null || true
ffmpeg -version > "$OUT/ffmpeg_version.txt" 2>/dev/null || true

# Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÐ½Ð¸Ð¼Ð¾Ðº Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
cat > "$OUT/runtime_check.txt" <<RUNTIME
WORKDIR: $(pwd)
USER: $(id -u -n) ($(id -u))
VENV: ${VIRTUAL_ENV:-none}
TELEGRAM_TOKEN_SET: $( [ -n "${TELEGRAM_TOKEN:-}" ] && echo yes || echo no )
OPENAI_API_KEY_SET: $( [ -n "${OPENAI_API_KEY:-}" ] && echo yes || echo no )
OPENAI_MODEL: ${OPENAI_MODEL:-unset}
TEMP_DIR: ${TEMP_DIR:-unset}
RUNTIME

# ÐŸÐ¾Ð»ÐµÐ·Ð½Ñ‹Ðµ grep Ð¿Ð¾ main.py (Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¹ Ð½Ð°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ð¸)
[ -f main.py ] && grep -nE "ApplicationBuilder|MessageHandler|filters\.VOICE|run_polling" main.py > "$OUT/main_handlers_grep.txt" || true

# Ð£Ð¿Ð°ÐºÐ¾Ð²ÐºÐ°
tar -czf "$OUT.tgz" -C "$(dirname "$OUT")" "$(basename "$OUT")"
echo "Bundle created: $OUT.tgz"
ls -lh "$OUT.tgz"
